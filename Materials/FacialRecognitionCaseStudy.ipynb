{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e443c6d",
   "metadata": {},
   "source": [
    "#### Some of the following code was sourced from: https://www.kaggle.com/code/gulsahdemiryurek/image-classification-with-logistic-regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868f1018",
   "metadata": {},
   "source": [
    "## In this exercise, you will be training an image classifier that utilizes logistic regression to classify facial images as either male or female. Due to past technologies falsely classifying people of color, we are particularly concerned about our classifier functioning well for all racial groups. While our classifier has already been constructed, we need to assemble the optimal training data set for an accurate and unbiased classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce498cd6",
   "metadata": {},
   "source": [
    "### To begin, we need to import all the necessary data. The data can be found here: https://github.com/lls4abt/FacialRecognitionCaseStudy/tree/master/Materials/Data\n",
    "\n",
    "### Download both the training and testing data sets nd store them somewhere you can easily access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5fc376",
   "metadata": {},
   "source": [
    "### Now let's start by building our classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22c9759",
   "metadata": {},
   "source": [
    "#### First, import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dd23699b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "import os \n",
    "from tqdm import tqdm \n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a02656",
   "metadata": {},
   "source": [
    "#### Let's create our train_data function which prepares our training images to be run through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7187b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(train_female, train_male, image_size):\n",
    "    train_data_female = [] \n",
    "    train_data_male=[]\n",
    "    for image1 in tqdm(os.listdir(train_female)): \n",
    "         if image1 != \".DS_Store\":\n",
    "            path = os.path.join(train_female, image1)\n",
    "            img1 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "            img1 = cv2.resize(img1, (image_size, image_size))\n",
    "            train_data_female.append(img1) \n",
    "    for image2 in tqdm(os.listdir(train_male)): \n",
    "        if image2 != \".DS_Store\":\n",
    "            path = os.path.join(train_male, image2)\n",
    "            img2 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "            img2 = cv2.resize(img2, (image_size, image_size))\n",
    "            train_data_male.append(img2) \n",
    "        \n",
    "    train_data= np.concatenate((np.asarray(train_data_female),np.asarray(train_data_male)),axis=0)\n",
    "    return train_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca1e213",
   "metadata": {},
   "source": [
    "#### Let's create our test_data function which prepares our testing images to be run through the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d48b5708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(test_female, test_male, image_size):\n",
    "    test_data_female = [] \n",
    "    test_data_male = []\n",
    "    for image1 in tqdm(os.listdir(test_female)): \n",
    "        if image1 != \".DS_Store\":\n",
    "            path = os.path.join(test_female, image1)\n",
    "            img1 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "            img1 = cv2.resize(img1, (image_size, image_size))\n",
    "            test_data_female.append(img1) \n",
    "    for image2 in tqdm(os.listdir(test_male)): \n",
    "        if image2 != \".DS_Store\":\n",
    "            path = os.path.join(test_male, image2)\n",
    "            img2 = cv2.imread(path, cv2.IMREAD_GRAYSCALE) \n",
    "            img2 = cv2.resize(img2, (image_size, image_size))\n",
    "            test_data_male.append(img2) \n",
    "    \n",
    "    test_data= np.concatenate((np.asarray(test_data_female),np.asarray(test_data_male)),axis=0) \n",
    "    return test_data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1d94f7",
   "metadata": {},
   "source": [
    "#### Now let's build our logistic regression classifier. The details about how this classifier works is not necessary to know, but if you'd like to learn more there are plenty of sources here: \n",
    "\n",
    "https://github.com/lls4abt/FacialRecognitionCaseStudy/tree/master/Materials/Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b97d22e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_bias(dimension):\n",
    "    w = np.full((dimension,1),0.01)\n",
    "    b = 0.0\n",
    "    return w, b\n",
    "\n",
    "def sigmoid(z):\n",
    "    y_head = 1/(1+np.exp(-z))\n",
    "    return y_head\n",
    "\n",
    "def forward_backward_propagation(w,b,x_train,y_train):\n",
    "    # forward propagation\n",
    "    z = np.dot(w.T,x_train) + b\n",
    "    y_head = sigmoid(z)\n",
    "    loss = -y_train*np.log(y_head)-(1-y_train)*np.log(1-y_head)\n",
    "    cost = (np.sum(loss))/x_train.shape[1]\n",
    "    # backward propagation\n",
    "    derivative_weight = (np.dot(x_train,((y_head-y_train).T)))/x_train.shape[1]\n",
    "    derivative_bias = np.sum(y_head-y_train)/x_train.shape[1]\n",
    "    gradients = {\"derivative_weight\": derivative_weight,\"derivative_bias\": derivative_bias}\n",
    "    return cost,gradients\n",
    "\n",
    "def update(w, b, x_train, y_train, learning_rate,number_of_iterarion):\n",
    "    cost_list = []\n",
    "    cost_list2 = []\n",
    "    index = []\n",
    "    \n",
    "    for i in range(number_of_iterarion):\n",
    "        \n",
    "        cost,gradients = forward_backward_propagation(w,b,x_train,y_train)\n",
    "        cost_list.append(cost)\n",
    "        \n",
    "        w = w - learning_rate * gradients[\"derivative_weight\"]\n",
    "        b = b - learning_rate * gradients[\"derivative_bias\"]\n",
    "        if i % 100 == 0:\n",
    "            cost_list2.append(cost)\n",
    "            index.append(i)\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    parameters = {\"weight\": w,\"bias\": b}\n",
    "    plt.plot(index,cost_list2)\n",
    "    plt.xticks(index,rotation='vertical')\n",
    "    plt.xlabel(\"Number of Iterarion\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.show()\n",
    "    return parameters, gradients, cost_list\n",
    "\n",
    "def predict(w,b,x_test):\n",
    "    \n",
    "    z = sigmoid(np.dot(w.T,x_test)+b)\n",
    "    Y_prediction = np.zeros((1,x_test.shape[1]))\n",
    "\n",
    "    for i in range(z.shape[1]):\n",
    "        if z[0,i]<= 0.5:\n",
    "            Y_prediction[0,i] = 0\n",
    "        else:\n",
    "            Y_prediction[0,i] = 1\n",
    "\n",
    "    return Y_prediction\n",
    "\n",
    "def logistic_regression(x_train, y_train, x_test, y_test, learning_rate, num_iterations):\n",
    "\n",
    "    dimension =  x_train.shape[0]\n",
    "    w,b = initialize_weights_and_bias(dimension)\n",
    "\n",
    "    parameters, gradients, cost_list = update(w, b, x_train, y_train, learning_rate,num_iterations)\n",
    "    \n",
    "    y_prediction_test = predict(parameters[\"weight\"],parameters[\"bias\"],x_test)\n",
    "    y_prediction_train = predict(parameters[\"weight\"],parameters[\"bias\"],x_train)\n",
    "    \n",
    "    print(\"Test Accuracy: {} %\".format(round(100 - np.mean(np.abs(y_prediction_test - y_test)) * 100,2)))\n",
    "    print(\"Train Accuracy: {} %\".format(round(100 - np.mean(np.abs(y_prediction_train - y_train)) * 100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1276013",
   "metadata": {},
   "source": [
    "#### Now this is where you come in. It's time to assemble our training data set. Our training set will consist of 1000 images and you will choose how many images from each racial group it will consist of. First we need to create a function that will pull images from our racial group folders. There are 4 racial groups: white, black, asian, other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "034330c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_images (source, num_images, dst_dir):\n",
    "    used_images = []\n",
    "    file_list = os.listdir(source)\n",
    "    i = 0\n",
    "    while i < num_images:\n",
    "        a = random.choice(file_list)\n",
    "        if a not in used_images:\n",
    "            if a != \".DS_Store\":\n",
    "                shutil.copy(source + a, dst_dir)\n",
    "                used_images.append(a)\n",
    "                i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27cb87",
   "metadata": {},
   "source": [
    "#### ACTION REQUIRED: Now let's select how many images from each racial group you want to include in the training data. The default only includes white images. Make sure your total adds up to 1000. Also remember to record the final inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43ae0818",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALTER THE FOLLOWING BASED ON HOW MANY IMAGES YOU WANT TO INCLUDE IN THE TRAINING SET FROM EACH RACIAL GROUP\n",
    "\n",
    "number_white = 1000\n",
    "number_asian = 0\n",
    "number_black = 0\n",
    "number_other = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29262ba5",
   "metadata": {},
   "source": [
    "#### ACTION REQUIRED: Now create the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "7060bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALTER THE FOLLOWING BASED ON PATHWAYS TO WHERE YOU STORED THE DATA\n",
    "\n",
    "dst_dir_f = \"Data/Train/TrainFemale/\" #this folder is already created but should be empty\n",
    "dst_dir_m = \"Data/Train/TrainMale/\" #this folder is already created but should be empty\n",
    "\n",
    "## The following folders should already contain images \n",
    "white_path_f = \"Data/Train/WhiteFemale/\" \n",
    "asian_path_f = \"Data/Train/AsianFemale/\"\n",
    "black_path_f = \"Data/Train/BlackFemale/\"\n",
    "other_path_f = \"Data/Train/OtherFemale/\"\n",
    "\n",
    "white_path_m = \"Data/Train/WhiteMale/\"\n",
    "asian_path_m = \"Data/Train/AsianMale/\"\n",
    "black_path_m = \"Data/Train/BlackMale/\"\n",
    "other_path_m = \"Data/Train/OtherMale/\"\n",
    "\n",
    "for f in os.listdir(dst_dir_f):\n",
    "    os.remove(os.path.join(dst_dir_f, f))\n",
    "    \n",
    "for f in os.listdir(dst_dir_m):\n",
    "    os.remove(os.path.join(dst_dir_m, f))  \n",
    "\n",
    "select_images(white_path_f, number_white, dst_dir_f)\n",
    "select_images(asian_path_f, number_asian, dst_dir_f)\n",
    "select_images(black_path_f, number_black, dst_dir_f)\n",
    "select_images(other_path_f, number_other, dst_dir_f) \n",
    "\n",
    "select_images(white_path_m, number_white, dst_dir_m)\n",
    "select_images(asian_path_m, number_asian, dst_dir_m)\n",
    "select_images(black_path_m, number_black, dst_dir_m)\n",
    "select_images(other_path_m, number_other, dst_dir_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "826ec98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALTER THE FOLLOWING BASED ON PATHWAYS TO WHERE YOU STORED THE DATA\n",
    "\n",
    "test_female_data = \"Data/Test/TestFemale/\"\n",
    "test_male_data = \"Data/Test/TestMale/\"\n",
    "\n",
    "train_female_data = \"Data/Train/TrainFemale/\"\n",
    "train_male_data = \"Data/Train/TrainMale/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c128908e",
   "metadata": {},
   "source": [
    "#### Now let's run our classifier with the training set you constructed. Our classifier will be trained with our training data set and then it will attempt to classify the 200 test images. A final accuracy will be returned. Remember to record this final test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7d3cc208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 5174.74it/s]\n",
      "100%|█████████████████████████████████████| 1000/1000 [00:00<00:00, 5214.66it/s]\n",
      "100%|███████████████████████████████████████| 101/101 [00:00<00:00, 3013.13it/s]\n",
      "100%|███████████████████████████████████████| 101/101 [00:00<00:00, 3092.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train flatten (1870, 16384)\n",
      "X test flatten (330, 16384)\n",
      "Cost after iteration 0: nan\n",
      "Cost after iteration 100: 2.398853\n",
      "Cost after iteration 200: 2.067858\n",
      "Cost after iteration 300: 1.794276\n",
      "Cost after iteration 400: 1.556494\n",
      "Cost after iteration 500: 1.330636\n",
      "Cost after iteration 600: 1.109059\n",
      "Cost after iteration 700: 0.909988\n",
      "Cost after iteration 800: 0.761304\n",
      "Cost after iteration 900: 0.651378\n",
      "Cost after iteration 1000: 0.565860\n",
      "Cost after iteration 1100: 0.504827\n",
      "Cost after iteration 1200: 0.317730\n",
      "Cost after iteration 1300: 0.278412\n",
      "Cost after iteration 1400: 0.269474\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.0 %\n",
      "Train Accuracy: 90.32 %\n"
     ]
    }
   ],
   "source": [
    "image_size = 128\n",
    "\n",
    "train_data = train_data(train_female_data, train_male_data, image_size) \n",
    "test_data = test_data(test_female_data, test_male_data, image_size)\n",
    "\n",
    "x_data=np.concatenate((train_data,test_data),axis=0)\n",
    "x_data = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))\n",
    "\n",
    "z1 = np.zeros(1000)\n",
    "o1 = np.ones(1000)\n",
    "Y_train = np.concatenate((o1, z1), axis=0)\n",
    "z = np.zeros(100)\n",
    "o = np.ones(100)\n",
    "Y_test = np.concatenate((o, z), axis=0)\n",
    "\n",
    "y_data=np.concatenate((Y_train,Y_test),axis=0).reshape(x_data.shape[0],1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.15, random_state=42)\n",
    "number_of_train = x_train.shape[0]\n",
    "number_of_test = x_test.shape[0]\n",
    "\n",
    "x_train_flatten = x_train.reshape(number_of_train,x_train.shape[1]*x_train.shape[2])\n",
    "x_test_flatten = x_test .reshape(number_of_test,x_test.shape[1]*x_test.shape[2])\n",
    "print(\"X train flatten\",x_train_flatten.shape)\n",
    "print(\"X test flatten\",x_test_flatten.shape)\n",
    "\n",
    "x_train = x_train_flatten.T\n",
    "x_test = x_test_flatten.T\n",
    "y_test = y_test.T\n",
    "y_train = y_train.T\n",
    "\n",
    "logistic_regression(x_train, y_train, x_test, y_test,learning_rate = 0.01, num_iterations = 1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92cfd60",
   "metadata": {},
   "source": [
    "### Make sure to record you're test accuarcy as well as the makeup of your training set. Run your classifier several more times trying different combinations for the training data set (don't worry about resetting your training set, the code will do this for you). What training set resulted in the highest test accuracy? Why do you think this is so? Are there any pattern or trends in inputs and outputs?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
